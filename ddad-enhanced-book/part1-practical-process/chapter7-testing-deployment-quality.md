# ç¬¬ä¸ƒç« ï¼šæµ‹è¯•éƒ¨ç½²ä¸è´¨é‡ä¿è¯

> **æœ¬ç« å¯¼è¯»**
>
> åœ¨AIé©±åŠ¨çš„å¼€å‘æµç¨‹ä¸­ï¼Œå¦‚ä½•ç¡®ä¿ä»£ç è´¨é‡å’Œç³»ç»Ÿç¨³å®šæ€§ï¼Ÿæœ¬ç« å°†æ·±å…¥æ¢è®¨DDADç¯å¢ƒä¸‹çš„æµ‹è¯•éƒ¨ç½²ä¸è´¨é‡ä¿è¯ä½“ç³»ï¼ŒåŒ…æ‹¬AIè¾…åŠ©æµ‹è¯•ç­–ç•¥ã€è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹ã€ç”Ÿäº§ç¯å¢ƒç›‘æ§ï¼Œä»¥åŠå¦‚ä½•å»ºç«‹å¯æŒç»­çš„è´¨é‡ä¿è¯æœºåˆ¶ã€‚æˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•è®©AIç”Ÿæˆçš„ä»£ç åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¨³å®šå¯é åœ°è¿è¡Œã€‚

---

## 7.1 AIé©±åŠ¨çš„æµ‹è¯•ç­–ç•¥

### 7.1.1 æµ‹è¯•èŒƒå¼è½¬å˜

ä¼ ç»Ÿæµ‹è¯•æµç¨‹å¾€å¾€æ˜¯å¼€å‘å®Œæˆåçš„"äº‹åæ£€éªŒ"ï¼Œè€Œåœ¨DDADæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬éœ€è¦å»ºç«‹"æµ‹è¯•å‰ç½®"çš„æ–°èŒƒå¼ï¼š

#### ä¼ ç»Ÿæµ‹è¯• vs AIé©±åŠ¨æµ‹è¯•

| ç»´åº¦ | ä¼ ç»Ÿæµ‹è¯• | AIé©±åŠ¨æµ‹è¯• |
|------|----------|------------|
| **æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ** | æ‰‹åŠ¨ç¼–å†™ï¼Œè€—æ—¶é•¿ | AIè‡ªåŠ¨ç”Ÿæˆï¼Œè¦†ç›–ç‡é«˜ |
| **æµ‹è¯•æ•°æ®å‡†å¤‡** | æ‰‹åŠ¨æ„é€ ï¼Œåœºæ™¯æœ‰é™ | AIç”Ÿæˆå¤šæ ·åŒ–æµ‹è¯•æ•°æ® |
| **å›å½’æµ‹è¯•** | æ‰‹åŠ¨æ‰§è¡Œï¼Œå®¹æ˜“é—æ¼ | è‡ªåŠ¨åŒ–æ‰§è¡Œï¼Œå…¨é¢è¦†ç›– |
| **æ€§èƒ½æµ‹è¯•** | å®šæœŸæ‰§è¡Œï¼Œåé¦ˆæ»å | æŒç»­ç›‘æ§ï¼Œå®æ—¶é¢„è­¦ |
| **ç¼ºé™·åˆ†æ** | äººå·¥åˆ†æï¼Œä¸»è§‚æ€§å¼º | AIè¾…åŠ©åˆ†æï¼Œå®¢è§‚å‡†ç¡® |

#### DDADæµ‹è¯•æ ¸å¿ƒåŸåˆ™

1. **æµ‹è¯•å³æ–‡æ¡£**ï¼šæµ‹è¯•ç”¨ä¾‹æœ¬èº«å°±æ˜¯æœ€å‡†ç¡®çš„åŠŸèƒ½è§„æ ¼è¯´æ˜
2. **è´¨é‡å†…å»º**ï¼šä»ç¬¬ä¸€è¡Œä»£ç å¼€å§‹å°±æœ‰å®Œæ•´çš„æµ‹è¯•è¦†ç›–
3. **æŒç»­éªŒè¯**ï¼šæ¯æ¬¡ä»£ç å˜æ›´éƒ½è§¦å‘å…¨é¢çš„è´¨é‡æ£€æŸ¥
4. **æ™ºèƒ½åˆ†æ**ï¼šåˆ©ç”¨AIåˆ†ææµ‹è¯•ç»“æœï¼Œé¢„æµ‹æ½œåœ¨é—®é¢˜

### 7.1.2 AIè¾…åŠ©æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ

#### åŸºäºéœ€æ±‚çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ

ä½¿ç”¨AIä»PRDå’Œç”¨æˆ·æ•…äº‹ä¸­è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼š

**Promptæ¨¡æ¿ï¼šæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ**

```markdown
# æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæç¤ºè¯

## è§’è‰²è®¾å®š
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ä»éœ€æ±‚æ–‡æ¡£ä¸­æå–æµ‹è¯•åœºæ™¯ï¼Œè®¾è®¡å…¨é¢çš„æµ‹è¯•ç”¨ä¾‹ã€‚

## ä»»åŠ¡æè¿°
åŸºäºä»¥ä¸‹åŠŸèƒ½éœ€æ±‚ï¼Œç”Ÿæˆå®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹é›†åˆï¼ŒåŒ…æ‹¬æ­£å¸¸æµç¨‹ã€å¼‚å¸¸æµç¨‹å’Œè¾¹ç•Œæ¡ä»¶æµ‹è¯•ã€‚

## è¾“å…¥ä¿¡æ¯
**åŠŸèƒ½éœ€æ±‚**ï¼š{åŠŸèƒ½æè¿°}
**éªŒæ”¶æ ‡å‡†**ï¼š{éªŒæ”¶æ¡ä»¶}
**æŠ€æœ¯çº¦æŸ**ï¼š{æŠ€æœ¯é™åˆ¶}

## è¾“å‡ºè¦æ±‚
1. **åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹**
   - æ­£å¸¸æµç¨‹æµ‹è¯•ï¼ˆHappy Pathï¼‰
   - å¼‚å¸¸æµç¨‹æµ‹è¯•ï¼ˆError Casesï¼‰
   - è¾¹ç•Œå€¼æµ‹è¯•ï¼ˆBoundary Testingï¼‰

2. **éåŠŸèƒ½æµ‹è¯•ç”¨ä¾‹**
   - æ€§èƒ½æµ‹è¯•åœºæ™¯
   - å®‰å…¨æµ‹è¯•åœºæ™¯
   - å…¼å®¹æ€§æµ‹è¯•åœºæ™¯

3. **æµ‹è¯•æ•°æ®è®¾è®¡**
   - æœ‰æ•ˆæ•°æ®é›†
   - æ— æ•ˆæ•°æ®é›†
   - è¾¹ç•Œæ•°æ®é›†

## è¾“å‡ºæ ¼å¼
ä½¿ç”¨æ ‡å‡†çš„æµ‹è¯•ç”¨ä¾‹æ ¼å¼ï¼ŒåŒ…å«ï¼šæµ‹è¯•IDã€æµ‹è¯•æ ‡é¢˜ã€å‰ç½®æ¡ä»¶ã€æµ‹è¯•æ­¥éª¤ã€é¢„æœŸç»“æœã€ä¼˜å…ˆçº§ã€‚
```

#### å®é™…åº”ç”¨ç¤ºä¾‹ï¼šTechMeetéŸ³é¢‘ä¸Šä¼ åŠŸèƒ½

**è¾“å…¥éœ€æ±‚**ï¼š
```markdown
åŠŸèƒ½ï¼šç”¨æˆ·å¯ä»¥ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶è¿›è¡Œä¼šè®®è½¬å½•
éªŒæ”¶æ ‡å‡†ï¼š
- æ”¯æŒMP3ã€WAVã€M4Aæ ¼å¼
- æ–‡ä»¶å¤§å°é™åˆ¶100MB
- ä¸Šä¼ è¿‡ç¨‹æ˜¾ç¤ºè¿›åº¦
- ä¸Šä¼ å¤±è´¥æ—¶æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
```

**AIç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹**ï¼š

```typescript
// tests/upload.test.ts
describe('éŸ³é¢‘ä¸Šä¼ åŠŸèƒ½æµ‹è¯•', () => {
  // æ­£å¸¸æµç¨‹æµ‹è¯•
  describe('æ­£å¸¸æµç¨‹', () => {
    test('TC001: æˆåŠŸä¸Šä¼ MP3æ–‡ä»¶', async () => {
      const file = new File(['audio content'], 'test.mp3', { type: 'audio/mpeg' });
      const result = await uploadAudio(file);
      
      expect(result.success).toBe(true);
      expect(result.fileUrl).toBeDefined();
      expect(result.meetingId).toBeDefined();
    });

    test('TC002: ä¸Šä¼ è¿‡ç¨‹æ˜¾ç¤ºè¿›åº¦', async () => {
      const file = new File(['audio content'], 'test.wav', { type: 'audio/wav' });
      const progressCallback = jest.fn();
      
      await uploadAudio(file, { onProgress: progressCallback });
      
      expect(progressCallback).toHaveBeenCalled();
      expect(progressCallback).toHaveBeenCalledWith(expect.objectContaining({
        loaded: expect.any(Number),
        total: expect.any(Number)
      }));
    });
  });

  // å¼‚å¸¸æµç¨‹æµ‹è¯•
  describe('å¼‚å¸¸æµç¨‹', () => {
    test('TC003: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼', async () => {
      const file = new File(['content'], 'test.txt', { type: 'text/plain' });
      
      await expect(uploadAudio(file)).rejects.toThrow('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼');
    });

    test('TC004: æ–‡ä»¶å¤§å°è¶…é™', async () => {
      const largeContent = 'x'.repeat(100 * 1024 * 1024 + 1); // è¶…è¿‡100MB
      const file = new File([largeContent], 'large.mp3', { type: 'audio/mpeg' });
      
      await expect(uploadAudio(file)).rejects.toThrow('æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡100MB');
    });

    test('TC005: ç½‘ç»œé”™è¯¯å¤„ç†', async () => {
      // æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯
      jest.spyOn(global, 'fetch').mockRejectedValue(new Error('Network Error'));
      
      const file = new File(['audio content'], 'test.mp3', { type: 'audio/mpeg' });
      
      await expect(uploadAudio(file)).rejects.toThrow('ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥');
    });
  });

  // è¾¹ç•Œå€¼æµ‹è¯•
  describe('è¾¹ç•Œå€¼æµ‹è¯•', () => {
    test('TC006: æœ€å¤§å…è®¸æ–‡ä»¶å¤§å°', async () => {
      const maxContent = 'x'.repeat(100 * 1024 * 1024); // æ°å¥½100MB
      const file = new File([maxContent], 'max.mp3', { type: 'audio/mpeg' });
      
      const result = await uploadAudio(file);
      expect(result.success).toBe(true);
    });

    test('TC007: æœ€å°æ–‡ä»¶å¤§å°', async () => {
      const file = new File(['x'], 'min.mp3', { type: 'audio/mpeg' });
      
      const result = await uploadAudio(file);
      expect(result.success).toBe(true);
    });
  });
});
```

### 7.1.3 æ™ºèƒ½æµ‹è¯•æ•°æ®ç”Ÿæˆ

#### AIç”ŸæˆçœŸå®æµ‹è¯•æ•°æ®

ä¼ ç»Ÿçš„æµ‹è¯•æ•°æ®å¾€å¾€è¿‡äºç®€å•ï¼Œæ— æ³•è¦†ç›–çœŸå®åœºæ™¯çš„å¤æ‚æ€§ã€‚ä½¿ç”¨AIå¯ä»¥ç”Ÿæˆæ›´è´´è¿‘çœŸå®ä¸šåŠ¡çš„æµ‹è¯•æ•°æ®ï¼š

```typescript
// lib/test-data-generator.ts
import { faker } from '@faker-js/faker';

export class AITestDataGenerator {
  // ç”Ÿæˆç”¨æˆ·æµ‹è¯•æ•°æ®
  static generateUsers(count: number = 10) {
    return Array.from({ length: count }, () => ({
      id: faker.string.uuid(),
      name: faker.person.fullName(),
      email: faker.internet.email(),
      avatar: faker.image.avatar(),
      createdAt: faker.date.past(),
      preferences: {
        language: faker.helpers.arrayElement(['zh-CN', 'en-US', 'ja-JP']),
        timezone: faker.location.timeZone(),
        notifications: faker.datatype.boolean()
      }
    }));
  }

  // ç”Ÿæˆä¼šè®®æµ‹è¯•æ•°æ®
  static generateMeetings(userIds: string[], count: number = 20) {
    return Array.from({ length: count }, () => ({
      id: faker.string.uuid(),
      title: faker.company.catchPhrase(),
      description: faker.lorem.paragraph(),
      hostId: faker.helpers.arrayElement(userIds),
      participants: faker.helpers.arrayElements(userIds, { min: 2, max: 8 }),
      startTime: faker.date.future(),
      duration: faker.number.int({ min: 30, max: 180 }), // 30-180åˆ†é’Ÿ
      status: faker.helpers.arrayElement(['scheduled', 'in_progress', 'completed', 'cancelled']),
      audioFile: {
        url: faker.internet.url(),
        size: faker.number.int({ min: 1024 * 1024, max: 100 * 1024 * 1024 }), // 1MB-100MB
        format: faker.helpers.arrayElement(['mp3', 'wav', 'm4a'])
      }
    }));
  }

  // ç”ŸæˆAIåˆ†æç»“æœæµ‹è¯•æ•°æ®
  static generateInsights(meetingId: string) {
    return {
      meetingId,
      transcription: faker.lorem.paragraphs(5),
      summary: faker.lorem.paragraph(),
      keyPoints: Array.from({ length: faker.number.int({ min: 3, max: 8 }) }, () => 
        faker.lorem.sentence()
      ),
      actionItems: Array.from({ length: faker.number.int({ min: 1, max: 5 }) }, () => ({
        id: faker.string.uuid(),
        description: faker.lorem.sentence(),
        assignee: faker.person.fullName(),
        dueDate: faker.date.future(),
        priority: faker.helpers.arrayElement(['high', 'medium', 'low'])
      })),
      decisions: Array.from({ length: faker.number.int({ min: 0, max: 3 }) }, () => ({
        id: faker.string.uuid(),
        description: faker.lorem.sentence(),
        context: faker.lorem.paragraph(),
        impact: faker.helpers.arrayElement(['high', 'medium', 'low'])
      }))
    };
  }
}
```

#### æ•°æ®é©±åŠ¨æµ‹è¯•

ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•æ•°æ®è¿›è¡Œå‚æ•°åŒ–æµ‹è¯•ï¼š

```typescript
// tests/meeting-analysis.test.ts
describe('ä¼šè®®åˆ†æåŠŸèƒ½', () => {
  let testUsers: any[];
  let testMeetings: any[];

  beforeAll(() => {
    testUsers = AITestDataGenerator.generateUsers(50);
    testMeetings = AITestDataGenerator.generateMeetings(
      testUsers.map(u => u.id), 
      100
    );
  });

  test.each(testMeetings.slice(0, 10))('åˆ†æä¼šè®®: $title', async (meeting) => {
    const insights = await analyzeMeeting(meeting.id);
    
    expect(insights).toMatchObject({
      meetingId: meeting.id,
      transcription: expect.any(String),
      summary: expect.any(String),
      keyPoints: expect.arrayContaining([expect.any(String)]),
      actionItems: expect.arrayContaining([
        expect.objectContaining({
          description: expect.any(String),
          assignee: expect.any(String)
        })
      ])
    });
  });
});
```

---

## 7.2 è‡ªåŠ¨åŒ–æµ‹è¯•ä½“ç³»

### 7.2.1 åˆ†å±‚æµ‹è¯•ç­–ç•¥

é‡‡ç”¨æµ‹è¯•é‡‘å­—å¡”æ¨¡å‹ï¼Œå»ºç«‹åˆ†å±‚çš„è‡ªåŠ¨åŒ–æµ‹è¯•ä½“ç³»ï¼š

```
        /\
       /  \
      / E2E \     <- å°‘é‡ç«¯åˆ°ç«¯æµ‹è¯•
     /______\
    /        \
   /Integration\ <- é€‚é‡é›†æˆæµ‹è¯•
  /__________\
 /            \
/  Unit Tests  \   <- å¤§é‡å•å…ƒæµ‹è¯•
/______________\
```

#### å•å…ƒæµ‹è¯•ï¼ˆUnit Testsï¼‰

**è¦†ç›–ç‡è¦æ±‚**ï¼šâ‰¥ 80%
**æ‰§è¡Œé¢‘ç‡**ï¼šæ¯æ¬¡ä»£ç æäº¤
**æµ‹è¯•èŒƒå›´**ï¼šå‡½æ•°ã€ç±»ã€ç»„ä»¶çš„ç‹¬ç«‹åŠŸèƒ½

```typescript
// tests/unit/audio-processor.test.ts
import { AudioProcessor } from '@/lib/audio-processor';

describe('AudioProcessor', () => {
  let processor: AudioProcessor;

  beforeEach(() => {
    processor = new AudioProcessor();
  });

  describe('validateFile', () => {
    test('åº”è¯¥æ¥å—æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶', () => {
      const validFile = new File(['content'], 'test.mp3', { type: 'audio/mpeg' });
      
      expect(() => processor.validateFile(validFile)).not.toThrow();
    });

    test('åº”è¯¥æ‹’ç»æ— æ•ˆçš„æ–‡ä»¶æ ¼å¼', () => {
      const invalidFile = new File(['content'], 'test.txt', { type: 'text/plain' });
      
      expect(() => processor.validateFile(invalidFile))
        .toThrow('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼');
    });

    test('åº”è¯¥æ‹’ç»è¶…å¤§æ–‡ä»¶', () => {
      const largeFile = new File(['x'.repeat(101 * 1024 * 1024)], 'large.mp3', { 
        type: 'audio/mpeg' 
      });
      
      expect(() => processor.validateFile(largeFile))
        .toThrow('æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡100MB');
    });
  });

  describe('extractMetadata', () => {
    test('åº”è¯¥æå–éŸ³é¢‘æ–‡ä»¶å…ƒæ•°æ®', async () => {
      const file = new File(['mock audio data'], 'test.mp3', { type: 'audio/mpeg' });
      
      const metadata = await processor.extractMetadata(file);
      
      expect(metadata).toMatchObject({
        duration: expect.any(Number),
        format: 'mp3',
        size: expect.any(Number)
      });
    });
  });
});
```

#### é›†æˆæµ‹è¯•ï¼ˆIntegration Testsï¼‰

**è¦†ç›–ç‡è¦æ±‚**ï¼šâ‰¥ 60%
**æ‰§è¡Œé¢‘ç‡**ï¼šæ¯æ¬¡PRåˆå¹¶
**æµ‹è¯•èŒƒå›´**ï¼šæ¨¡å—é—´äº¤äº’ã€APIé›†æˆã€æ•°æ®åº“æ“ä½œ

```typescript
// tests/integration/meeting-workflow.test.ts
import { createTestClient } from '@/lib/test-utils';
import { setupTestDatabase, cleanupTestDatabase } from '@/lib/test-db';

describe('ä¼šè®®å·¥ä½œæµé›†æˆæµ‹è¯•', () => {
  let client: any;
  let testUser: any;

  beforeAll(async () => {
    await setupTestDatabase();
    client = createTestClient();
    testUser = await client.createUser({
      name: 'Test User',
      email: 'test@example.com'
    });
  });

  afterAll(async () => {
    await cleanupTestDatabase();
  });

  test('å®Œæ•´çš„ä¼šè®®å¤„ç†æµç¨‹', async () => {
    // 1. åˆ›å»ºä¼šè®®
    const meeting = await client.createMeeting({
      title: 'æµ‹è¯•ä¼šè®®',
      hostId: testUser.id
    });

    expect(meeting.id).toBeDefined();
    expect(meeting.status).toBe('created');

    // 2. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
    const audioFile = new File(['mock audio'], 'test.mp3', { type: 'audio/mpeg' });
    const uploadResult = await client.uploadAudio(meeting.id, audioFile);

    expect(uploadResult.success).toBe(true);
    expect(uploadResult.fileUrl).toBeDefined();

    // 3. è§¦å‘AIåˆ†æ
    const analysisResult = await client.analyzeMeeting(meeting.id);

    expect(analysisResult.status).toBe('processing');

    // 4. ç­‰å¾…åˆ†æå®Œæˆï¼ˆæ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†ï¼‰
    await new Promise(resolve => setTimeout(resolve, 1000));

    // 5. è·å–åˆ†æç»“æœ
    const insights = await client.getMeetingInsights(meeting.id);

    expect(insights).toMatchObject({
      transcription: expect.any(String),
      summary: expect.any(String),
      keyPoints: expect.any(Array),
      actionItems: expect.any(Array)
    });

    // 6. éªŒè¯æ•°æ®åº“çŠ¶æ€
    const updatedMeeting = await client.getMeeting(meeting.id);
    expect(updatedMeeting.status).toBe('analyzed');
  });
});
```

#### ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆE2E Testsï¼‰

**è¦†ç›–ç‡è¦æ±‚**ï¼šâ‰¥ 30%ï¼ˆå…³é”®ç”¨æˆ·è·¯å¾„ï¼‰
**æ‰§è¡Œé¢‘ç‡**ï¼šæ¯æ—¥æ„å»º
**æµ‹è¯•èŒƒå›´**ï¼šå®Œæ•´ç”¨æˆ·åœºæ™¯ã€è·¨æµè§ˆå™¨å…¼å®¹æ€§

```typescript
// tests/e2e/meeting-flow.spec.ts
import { test, expect } from '@playwright/test';

test.describe('ä¼šè®®ç®¡ç†ç«¯åˆ°ç«¯æµ‹è¯•', () => {
  test('ç”¨æˆ·å¯ä»¥åˆ›å»ºä¼šè®®å¹¶ä¸Šä¼ éŸ³é¢‘', async ({ page }) => {
    // 1. ç™»å½•
    await page.goto('/login');
    await page.fill('[data-testid=email]', 'test@example.com');
    await page.fill('[data-testid=password]', 'password123');
    await page.click('[data-testid=login-button]');

    // 2. å¯¼èˆªåˆ°ä¼šè®®é¡µé¢
    await page.click('[data-testid=meetings-nav]');
    await expect(page).toHaveURL('/meetings');

    // 3. åˆ›å»ºæ–°ä¼šè®®
    await page.click('[data-testid=create-meeting-button]');
    await page.fill('[data-testid=meeting-title]', 'ç«¯åˆ°ç«¯æµ‹è¯•ä¼šè®®');
    await page.fill('[data-testid=meeting-description]', 'è¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–æµ‹è¯•ä¼šè®®');
    await page.click('[data-testid=save-meeting-button]');

    // 4. éªŒè¯ä¼šè®®åˆ›å»ºæˆåŠŸ
    await expect(page.locator('[data-testid=meeting-title]')).toContainText('ç«¯åˆ°ç«¯æµ‹è¯•ä¼šè®®');

    // 5. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
    const fileInput = page.locator('[data-testid=audio-upload-input]');
    await fileInput.setInputFiles('tests/fixtures/sample-audio.mp3');

    // 6. éªŒè¯ä¸Šä¼ è¿›åº¦
    await expect(page.locator('[data-testid=upload-progress]')).toBeVisible();
    
    // 7. ç­‰å¾…ä¸Šä¼ å®Œæˆ
    await expect(page.locator('[data-testid=upload-success]')).toBeVisible({ timeout: 30000 });

    // 8. éªŒè¯åˆ†æå¼€å§‹
    await expect(page.locator('[data-testid=analysis-status]')).toContainText('åˆ†æä¸­');

    // 9. ç­‰å¾…åˆ†æå®Œæˆ
    await expect(page.locator('[data-testid=transcription]')).toBeVisible({ timeout: 60000 });

    // 10. éªŒè¯åˆ†æç»“æœ
    await expect(page.locator('[data-testid=summary]')).toBeVisible();
    await expect(page.locator('[data-testid=action-items]')).toBeVisible();
  });

  test('ç”¨æˆ·å¯ä»¥æŸ¥çœ‹å’Œç¼–è¾‘è¡ŒåŠ¨é¡¹', async ({ page }) => {
    // å‰ç½®æ¡ä»¶ï¼šå·²æœ‰åˆ†æå®Œæˆçš„ä¼šè®®
    await page.goto('/meetings/test-meeting-id');

    // 1. æŸ¥çœ‹è¡ŒåŠ¨é¡¹åˆ—è¡¨
    await expect(page.locator('[data-testid=action-items-list]')).toBeVisible();

    // 2. ç¼–è¾‘ç¬¬ä¸€ä¸ªè¡ŒåŠ¨é¡¹
    await page.click('[data-testid=action-item-edit]:first-child');
    await page.fill('[data-testid=action-item-description]', 'æ›´æ–°çš„è¡ŒåŠ¨é¡¹æè¿°');
    await page.selectOption('[data-testid=action-item-priority]', 'high');
    await page.click('[data-testid=save-action-item]');

    // 3. éªŒè¯æ›´æ–°æˆåŠŸ
    await expect(page.locator('[data-testid=action-item-description]:first-child'))
      .toContainText('æ›´æ–°çš„è¡ŒåŠ¨é¡¹æè¿°');
    await expect(page.locator('[data-testid=action-item-priority]:first-child'))
      .toContainText('é«˜ä¼˜å…ˆçº§');
  });
});
```

### 7.2.2 æ€§èƒ½æµ‹è¯•è‡ªåŠ¨åŒ–

#### å‰ç«¯æ€§èƒ½æµ‹è¯•

ä½¿ç”¨Lighthouse CIè¿›è¡Œè‡ªåŠ¨åŒ–æ€§èƒ½æµ‹è¯•ï¼š

```yaml
# .github/workflows/performance.yml
name: Performance Testing

on:
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 2 * * *' # æ¯æ—¥å‡Œæ™¨2ç‚¹æ‰§è¡Œ

jobs:
  lighthouse:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Build application
        run: npm run build
        
      - name: Start server
        run: npm start &
        
      - name: Wait for server
        run: npx wait-on http://localhost:3000
        
      - name: Run Lighthouse CI
        run: |
          npm install -g @lhci/cli@0.12.x
          lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
```

**Lighthouseé…ç½®æ–‡ä»¶**ï¼š

```json
// lighthouserc.json
{
  "ci": {
    "collect": {
      "url": [
        "http://localhost:3000",
        "http://localhost:3000/meetings",
        "http://localhost:3000/meetings/new"
      ],
      "numberOfRuns": 3
    },
    "assert": {
      "assertions": {
        "categories:performance": ["warn", {"minScore": 0.8}],
        "categories:accessibility": ["error", {"minScore": 0.9}],
        "categories:best-practices": ["error", {"minScore": 0.9}],
        "categories:seo": ["warn", {"minScore": 0.8}]
      }
    },
    "upload": {
      "target": "temporary-public-storage"
    }
  }
}
```

#### åç«¯æ€§èƒ½æµ‹è¯•

ä½¿ç”¨K6è¿›è¡ŒAPIæ€§èƒ½æµ‹è¯•ï¼š

```javascript
// tests/performance/api-load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

// è‡ªå®šä¹‰æŒ‡æ ‡
export const errorRate = new Rate('errors');

export const options = {
  stages: [
    { duration: '2m', target: 10 }, // é¢„çƒ­
    { duration: '5m', target: 50 }, // æ­£å¸¸è´Ÿè½½
    { duration: '2m', target: 100 }, // å³°å€¼è´Ÿè½½
    { duration: '5m', target: 100 }, // æŒç»­å³°å€¼
    { duration: '2m', target: 0 }, // é™è´Ÿè½½
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95%çš„è¯·æ±‚å“åº”æ—¶é—´å°äº500ms
    http_req_failed: ['rate<0.1'], // é”™è¯¯ç‡å°äº10%
    errors: ['rate<0.1'],
  },
};

const BASE_URL = 'http://localhost:3000/api';

export function setup() {
  // åˆ›å»ºæµ‹è¯•ç”¨æˆ·
  const loginRes = http.post(`${BASE_URL}/auth/login`, {
    email: 'test@example.com',
    password: 'password123'
  });
  
  return { token: loginRes.json('token') };
}

export default function(data) {
  const headers = {
    'Authorization': `Bearer ${data.token}`,
    'Content-Type': 'application/json',
  };

  // æµ‹è¯•åœºæ™¯1ï¼šè·å–ä¼šè®®åˆ—è¡¨
  const meetingsRes = http.get(`${BASE_URL}/meetings`, { headers });
  check(meetingsRes, {
    'è·å–ä¼šè®®åˆ—è¡¨æˆåŠŸ': (r) => r.status === 200,
    'å“åº”æ—¶é—´åˆç†': (r) => r.timings.duration < 300,
  }) || errorRate.add(1);

  sleep(1);

  // æµ‹è¯•åœºæ™¯2ï¼šåˆ›å»ºä¼šè®®
  const createMeetingRes = http.post(`${BASE_URL}/meetings`, JSON.stringify({
    title: `æ€§èƒ½æµ‹è¯•ä¼šè®® ${Date.now()}`,
    description: 'è¿™æ˜¯ä¸€ä¸ªæ€§èƒ½æµ‹è¯•ä¼šè®®'
  }), { headers });
  
  check(createMeetingRes, {
    'åˆ›å»ºä¼šè®®æˆåŠŸ': (r) => r.status === 201,
    'å“åº”æ—¶é—´åˆç†': (r) => r.timings.duration < 500,
  }) || errorRate.add(1);

  const meetingId = createMeetingRes.json('id');

  sleep(1);

  // æµ‹è¯•åœºæ™¯3ï¼šä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰
  const uploadRes = http.post(`${BASE_URL}/meetings/${meetingId}/upload`, {
    file: http.file('sample-audio.mp3', 'mock audio content', 'audio/mpeg')
  }, { headers });

  check(uploadRes, {
    'ä¸Šä¼ éŸ³é¢‘æˆåŠŸ': (r) => r.status === 200,
    'å“åº”æ—¶é—´åˆç†': (r) => r.timings.duration < 2000,
  }) || errorRate.add(1);

  sleep(2);
}
```

---

## 7.3 è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹

### 7.3.1 CI/CDæµæ°´çº¿è®¾è®¡

å»ºç«‹å®Œæ•´çš„CI/CDæµæ°´çº¿ï¼Œå®ç°ä»ä»£ç æäº¤åˆ°ç”Ÿäº§éƒ¨ç½²çš„å…¨è‡ªåŠ¨åŒ–ï¼š

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  NODE_VERSION: '18'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ä»£ç è´¨é‡æ£€æŸ¥
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Lint check
        run: npm run lint
        
      - name: Type check
        run: npm run type-check
        
      - name: Format check
        run: npm run format:check

  # å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
  test:
    runs-on: ubuntu-latest
    needs: quality-check
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: techmeet_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run unit tests
        run: npm run test:unit
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/techmeet_test
          REDIS_URL: redis://localhost:6379
          
      - name: Run integration tests
        run: npm run test:integration
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/techmeet_test
          REDIS_URL: redis://localhost:6379
          
      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info

  # E2Eæµ‹è¯•
  e2e-test:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'pull_request'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install Playwright
        run: npx playwright install --with-deps
        
      - name: Build application
        run: npm run build
        
      - name: Start application
        run: npm start &
        
      - name: Wait for application
        run: npx wait-on http://localhost:3000
        
      - name: Run E2E tests
        run: npm run test:e2e
        
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: e2e-test-results
          path: test-results/

  # æ„å»ºDockeré•œåƒ
  build:
    runs-on: ubuntu-latest
    needs: [test]
    if: github.ref == 'refs/heads/main'
    
    outputs:
      image: ${{ steps.image.outputs.image }}
      digest: ${{ steps.build.outputs.digest }}
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v2
        
      - name: Login to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            
      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
      - name: Output image
        id: image
        run: |
          echo "image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}" >> $GITHUB_OUTPUT

  # éƒ¨ç½²åˆ°é¢„å‘å¸ƒç¯å¢ƒ
  deploy-staging:
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
      - name: Deploy to staging
        run: |
          echo "Deploying ${{ needs.build.outputs.image }} to staging environment"
          # è¿™é‡Œå¯ä»¥é›†æˆå…·ä½“çš„éƒ¨ç½²è„šæœ¬
          # ä¾‹å¦‚ï¼škubectl, helm, terraformç­‰
          
  # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
  deploy-production:
    runs-on: ubuntu-latest
    needs: [build, deploy-staging]
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
      - name: Deploy to production
        run: |
          echo "Deploying ${{ needs.build.outputs.image }} to production environment"
          # ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è„šæœ¬
```

### 7.3.2 å¤šç¯å¢ƒéƒ¨ç½²ç­–ç•¥

#### ç¯å¢ƒé…ç½®ç®¡ç†

ä½¿ç”¨ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶ç®¡ç†ä¸åŒç¯å¢ƒçš„é…ç½®ï¼š

```typescript
// lib/config.ts
export interface AppConfig {
  app: {
    name: string;
    version: string;
    env: 'development' | 'staging' | 'production';
    port: number;
  };
  database: {
    url: string;
    maxConnections: number;
  };
  redis: {
    url: string;
  };
  ai: {
    openaiApiKey: string;
    model: string;
  };
  storage: {
    supabaseUrl: string;
    supabaseKey: string;
    bucket: string;
  };
  monitoring: {
    sentryDsn?: string;
    logLevel: 'debug' | 'info' | 'warn' | 'error';
  };
}

function loadConfig(): AppConfig {
  const env = process.env.NODE_ENV as AppConfig['app']['env'] || 'development';
  
  const baseConfig: AppConfig = {
    app: {
      name: 'TechMeet',
      version: process.env.npm_package_version || '1.0.0',
      env,
      port: parseInt(process.env.PORT || '3000', 10),
    },
    database: {
      url: process.env.DATABASE_URL || 'postgresql://localhost:5432/techmeet',
      maxConnections: parseInt(process.env.DB_MAX_CONNECTIONS || '10', 10),
    },
    redis: {
      url: process.env.REDIS_URL || 'redis://localhost:6379',
    },
    ai: {
      openaiApiKey: process.env.OPENAI_API_KEY || '',
      model: process.env.OPENAI_MODEL || 'gpt-4',
    },
    storage: {
      supabaseUrl: process.env.SUPABASE_URL || '',
      supabaseKey: process.env.SUPABASE_ANON_KEY || '',
      bucket: process.env.SUPABASE_BUCKET || 'audio-files',
    },
    monitoring: {
      sentryDsn: process.env.SENTRY_DSN,
      logLevel: (process.env.LOG_LEVEL as any) || 'info',
    },
  };

  // ç¯å¢ƒç‰¹å®šé…ç½®
  const envConfigs = {
    development: {
      monitoring: {
        ...baseConfig.monitoring,
        logLevel: 'debug' as const,
      },
    },
    staging: {
      ai: {
        ...baseConfig.ai,
        model: 'gpt-3.5-turbo', // é¢„å‘å¸ƒç¯å¢ƒä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
      },
    },
    production: {
      database: {
        ...baseConfig.database,
        maxConnections: 50, // ç”Ÿäº§ç¯å¢ƒå¢åŠ è¿æ¥æ•°
      },
    },
  };

  return {
    ...baseConfig,
    ...envConfigs[env],
  };
}

export const config = loadConfig();
```

#### Dockerå¤šé˜¶æ®µæ„å»º

```dockerfile
# Dockerfile
# ---- Base Stage ----
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# ---- Build Stage ----
FROM node:18-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# ---- Production Stage ----
FROM node:18-alpine AS production
WORKDIR /app

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

# å¤åˆ¶æ„å»ºäº§ç‰©å’Œä¾èµ–
COPY --from=base /app/node_modules ./node_modules
COPY --from=build --chown=nextjs:nodejs /app/.next ./.next
COPY --from=build /app/public ./public
COPY --from=build /app/package.json ./package.json

USER nextjs

EXPOSE 3000

ENV NODE_ENV=production
ENV PORT=3000

CMD ["npm", "start"]
```

#### Kuberneteséƒ¨ç½²é…ç½®

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: techmeet-app
  labels:
    app: techmeet
spec:
  replicas: 3
  selector:
    matchLabels:
      app: techmeet
  template:
    metadata:
      labels:
        app: techmeet
    spec:
      containers:
      - name: app
        image: ghcr.io/your-org/techmeet:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: techmeet-secrets
              key: database-url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: techmeet-secrets
              key: openai-api-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: techmeet-service
spec:
  selector:
    app: techmeet
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: LoadBalancer
```

---

## 7.4 ç”Ÿäº§ç¯å¢ƒç›‘æ§

### 7.4.1 åº”ç”¨æ€§èƒ½ç›‘æ§ï¼ˆAPMï¼‰

#### Sentryé›†æˆ

```typescript
// lib/monitoring/sentry.ts
import * as Sentry from '@sentry/nextjs';
import { config } from '@/lib/config';

export function initSentry() {
  Sentry.init({
    dsn: config.monitoring.sentryDsn,
    environment: config.app.env,
    tracesSampleRate: config.app.env === 'production' ? 0.1 : 1.0,
    
    beforeSend(event, hint) {
      // è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
      if (event.request?.headers) {
        delete event.request.headers.authorization;
        delete event.request.headers.cookie;
      }
      
      // è¿‡æ»¤ç‰¹å®šé”™è¯¯
      if (event.exception) {
        const error = hint.originalException;
        if (error instanceof Error && error.message.includes('Network Error')) {
          return null; // ä¸ä¸ŠæŠ¥ç½‘ç»œé”™è¯¯
        }
      }
      
      return event;
    },
    
    integrations: [
      new Sentry.Integrations.Http({ tracing: true }),
      new Sentry.Integrations.Express({ app: undefined }),
    ],
  });
}

// æ€§èƒ½ç›‘æ§è£…é¥°å™¨
export function withPerformanceMonitoring<T extends (...args: any[]) => any>(
  operation: string,
  fn: T
): T {
  return ((...args: any[]) => {
    const transaction = Sentry.startTransaction({
      name: operation,
      op: 'function',
    });
    
    Sentry.getCurrentHub().configureScope(scope => scope.setSpan(transaction));
    
    try {
      const result = fn(...args);
      
      if (result instanceof Promise) {
        return result
          .then(value => {
            transaction.setStatus('ok');
            transaction.finish();
            return value;
          })
          .catch(error => {
            transaction.setStatus('internal_error');
            Sentry.captureException(error);
            transaction.finish();
            throw error;
          });
      }
      
      transaction.setStatus('ok');
      transaction.finish();
      return result;
    } catch (error) {
      transaction.setStatus('internal_error');
      Sentry.captureException(error);
      transaction.finish();
      throw error;
    }
  }) as T;
}
```

#### è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†

```typescript
// lib/monitoring/metrics.ts
import { createPrometheusMetrics } from 'prom-client';

class MetricsCollector {
  private static instance: MetricsCollector;
  private metrics: any = {};

  private constructor() {
    this.initMetrics();
  }

  static getInstance(): MetricsCollector {
    if (!MetricsCollector.instance) {
      MetricsCollector.instance = new MetricsCollector();
    }
    return MetricsCollector.instance;
  }

  private initMetrics() {
    const promClient = require('prom-client');
    
    // åˆ›å»ºé»˜è®¤æŒ‡æ ‡
    promClient.collectDefaultMetrics();
    
    // è‡ªå®šä¹‰ä¸šåŠ¡æŒ‡æ ‡
    this.metrics = {
      // HTTPè¯·æ±‚è®¡æ•°å™¨
      httpRequestsTotal: new promClient.Counter({
        name: 'http_requests_total',
        help: 'Total number of HTTP requests',
        labelNames: ['method', 'route', 'status_code'],
      }),
      
      // HTTPè¯·æ±‚æŒç»­æ—¶é—´
      httpRequestDuration: new promClient.Histogram({
        name: 'http_request_duration_seconds',
        help: 'Duration of HTTP requests in seconds',
        labelNames: ['method', 'route'],
        buckets: [0.1, 0.5, 1, 2, 5],
      }),
      
      // éŸ³é¢‘å¤„ç†æŒ‡æ ‡
      audioProcessingDuration: new promClient.Histogram({
        name: 'audio_processing_duration_seconds',
        help: 'Duration of audio processing in seconds',
        labelNames: ['file_size_mb'],
        buckets: [1, 5, 10, 30, 60, 120],
      }),
      
      // AI APIè°ƒç”¨æŒ‡æ ‡
      aiApiCalls: new promClient.Counter({
        name: 'ai_api_calls_total',
        help: 'Total number of AI API calls',
        labelNames: ['provider', 'model', 'status'],
      }),
      
      // ç”¨æˆ·æ´»è·ƒåº¦æŒ‡æ ‡
      activeUsers: new promClient.Gauge({
        name: 'active_users_current',
        help: 'Current number of active users',
      }),
      
      // ä¼šè®®å¤„ç†æŒ‡æ ‡
      meetingsProcessed: new promClient.Counter({
        name: 'meetings_processed_total',
        help: 'Total number of meetings processed',
        labelNames: ['status'],
      }),
    };
  }

  // è®°å½•HTTPè¯·æ±‚
  recordHttpRequest(method: string, route: string, statusCode: number, duration: number) {
    this.metrics.httpRequestsTotal.inc({ method, route, status_code: statusCode });
    this.metrics.httpRequestDuration.observe({ method, route }, duration);
  }

  // è®°å½•éŸ³é¢‘å¤„ç†
  recordAudioProcessing(fileSizeMB: number, duration: number) {
    const sizeCategory = fileSizeMB < 10 ? 'small' : fileSizeMB < 50 ? 'medium' : 'large';
    this.metrics.audioProcessingDuration.observe({ file_size_mb: sizeCategory }, duration);
  }

  // è®°å½•AI APIè°ƒç”¨
  recordAiApiCall(provider: string, model: string, status: 'success' | 'error') {
    this.metrics.aiApiCalls.inc({ provider, model, status });
  }

  // æ›´æ–°æ´»è·ƒç”¨æˆ·æ•°
  updateActiveUsers(count: number) {
    this.metrics.activeUsers.set(count);
  }

  // è®°å½•ä¼šè®®å¤„ç†
  recordMeetingProcessed(status: 'success' | 'error') {
    this.metrics.meetingsProcessed.inc({ status });
  }

  // è·å–æ‰€æœ‰æŒ‡æ ‡
  getMetrics() {
    const promClient = require('prom-client');
    return promClient.register.metrics();
  }
}

export const metricsCollector = MetricsCollector.getInstance();
```

### 7.4.2 æ—¥å¿—ç®¡ç†

#### ç»“æ„åŒ–æ—¥å¿—

```typescript
// lib/logging/logger.ts
import winston from 'winston';
import { config } from '@/lib/config';

// è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼
const logFormat = winston.format.combine(
  winston.format.timestamp(),
  winston.format.errors({ stack: true }),
  winston.format.json(),
  winston.format.printf(({ timestamp, level, message, ...meta }) => {
    return JSON.stringify({
      timestamp,
      level,
      message,
      service: 'techmeet',
      environment: config.app.env,
      version: config.app.version,
      ...meta,
    });
  })
);

// åˆ›å»ºloggerå®ä¾‹
export const logger = winston.createLogger({
  level: config.monitoring.logLevel,
  format: logFormat,
  defaultMeta: {
    service: 'techmeet',
    environment: config.app.env,
  },
  transports: [
    // æ§åˆ¶å°è¾“å‡º
    new winston.transports.Console({
      format: config.app.env === 'development' 
        ? winston.format.combine(
            winston.format.colorize(),
            winston.format.simple()
          )
        : logFormat,
    }),
    
    // æ–‡ä»¶è¾“å‡ºï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
    ...(config.app.env === 'production' ? [
      new winston.transports.File({
        filename: 'logs/error.log',
        level: 'error',
        maxsize: 5242880, // 5MB
        maxFiles: 5,
      }),
      new winston.transports.File({
        filename: 'logs/combined.log',
        maxsize: 5242880, // 5MB
        maxFiles: 5,
      }),
    ] : []),
  ],
});

// è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
export function requestLogger(req: any, res: any, next: any) {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - start;
    
    logger.info('HTTP Request', {
      method: req.method,
      url: req.url,
      statusCode: res.statusCode,
      duration,
      userAgent: req.get('User-Agent'),
      ip: req.ip,
      userId: req.user?.id,
    });
  });
  
  next();
}

// ä¸šåŠ¡æ—¥å¿—è®°å½•å™¨
export class BusinessLogger {
  static logUserAction(userId: string, action: string, details?: any) {
    logger.info('User Action', {
      userId,
      action,
      details,
      category: 'user_behavior',
    });
  }

  static logMeetingEvent(meetingId: string, event: string, details?: any) {
    logger.info('Meeting Event', {
      meetingId,
      event,
      details,
      category: 'meeting_lifecycle',
    });
  }

  static logAiOperation(operation: string, duration: number, details?: any) {
    logger.info('AI Operation', {
      operation,
      duration,
      details,
      category: 'ai_processing',
    });
  }

  static logError(error: Error, context?: any) {
    logger.error('Application Error', {
      error: {
        name: error.name,
        message: error.message,
        stack: error.stack,
      },
      context,
      category: 'application_error',
    });
  }
}
```

### 7.4.3 å¥åº·æ£€æŸ¥å’Œå‘Šè­¦

#### å¥åº·æ£€æŸ¥ç«¯ç‚¹

```typescript
// pages/api/health.ts
import { NextApiRequest, NextApiResponse } from 'next';
import { logger } from '@/lib/logging/logger';
import { config } from '@/lib/config';

interface HealthCheck {
  status: 'healthy' | 'unhealthy';
  timestamp: string;
  version: string;
  environment: string;
  checks: {
    database: 'up' | 'down';
    redis: 'up' | 'down';
    storage: 'up' | 'down';
    ai_service: 'up' | 'down';
  };
  uptime: number;
}

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<HealthCheck>
) {
  const startTime = Date.now();
  
  try {
    // æ£€æŸ¥æ•°æ®åº“è¿æ¥
    const dbCheck = await checkDatabase();
    
    // æ£€æŸ¥Redisè¿æ¥
    const redisCheck = await checkRedis();
    
    // æ£€æŸ¥å­˜å‚¨æœåŠ¡
    const storageCheck = await checkStorage();
    
    // æ£€æŸ¥AIæœåŠ¡
    const aiServiceCheck = await checkAiService();
    
    const allHealthy = [dbCheck, redisCheck, storageCheck, aiServiceCheck]
      .every(check => check === 'up');
    
    const healthStatus: HealthCheck = {
      status: allHealthy ? 'healthy' : 'unhealthy',
      timestamp: new Date().toISOString(),
      version: config.app.version,
      environment: config.app.env,
      checks: {
        database: dbCheck,
        redis: redisCheck,
        storage: storageCheck,
        ai_service: aiServiceCheck,
      },
      uptime: process.uptime(),
    };
    
    const statusCode = allHealthy ? 200 : 503;
    
    logger.info('Health Check', {
      status: healthStatus.status,
      duration: Date.now() - startTime,
      checks: healthStatus.checks,
    });
    
    res.status(statusCode).json(healthStatus);
  } catch (error) {
    logger.error('Health Check Failed', { error });
    
    res.status(503).json({
      status: 'unhealthy',
      timestamp: new Date().toISOString(),
      version: config.app.version,
      environment: config.app.env,
      checks: {
        database: 'down',
        redis: 'down',
        storage: 'down',
        ai_service: 'down',
      },
      uptime: process.uptime(),
    });
  }
}

async function checkDatabase(): Promise<'up' | 'down'> {
  try {
    // å®ç°æ•°æ®åº“è¿æ¥æ£€æŸ¥
    // const result = await db.raw('SELECT 1');
    return 'up';
  } catch (error) {
    return 'down';
  }
}

async function checkRedis(): Promise<'up' | 'down'> {
  try {
    // å®ç°Redisè¿æ¥æ£€æŸ¥
    // await redis.ping();
    return 'up';
  } catch (error) {
    return 'down';
  }
}

async function checkStorage(): Promise<'up' | 'down'> {
  try {
    // å®ç°å­˜å‚¨æœåŠ¡æ£€æŸ¥
    // await supabase.storage.from('test').list();
    return 'up';
  } catch (error) {
    return 'down';
  }
}

async function checkAiService(): Promise<'up' | 'down'> {
  try {
    // å®ç°AIæœåŠ¡æ£€æŸ¥
    // await openai.models.list();
    return 'up';
  } catch (error) {
    return 'down';
  }
}
```

#### å‘Šè­¦é…ç½®

```yaml
# monitoring/alerts.yml
groups:
  - name: techmeet-alerts
    rules:
      # åº”ç”¨å¯ç”¨æ€§å‘Šè­¦
      - alert: ApplicationDown
        expr: up{job="techmeet"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "TechMeet application is down"
          description: "TechMeet application has been down for more than 1 minute"

      # é«˜é”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: rate(http_requests_total{status_code=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      # å“åº”æ—¶é—´å‘Šè­¦
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }} seconds"

      # æ•°æ®åº“è¿æ¥å‘Šè­¦
      - alert: DatabaseConnectionFailed
        expr: up{job="postgres"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Database connection failed"
          description: "Cannot connect to PostgreSQL database"

      # AIæœåŠ¡å‘Šè­¦
      - alert: AiServiceHighLatency
        expr: histogram_quantile(0.95, rate(audio_processing_duration_seconds_bucket[10m])) > 60
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "AI service high latency"
          description: "95th percentile AI processing time is {{ $value }} seconds"

      # ç£ç›˜ç©ºé—´å‘Šè­¦
      - alert: DiskSpaceHigh
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space usage high"
          description: "Disk space usage is {{ $value | humanizePercentage }}"
```

---

## 7.5 è´¨é‡ä¿è¯ä½“ç³»

### 7.5.1 è´¨é‡é—¨ç¦æ ‡å‡†

å»ºç«‹å¤šå±‚æ¬¡çš„è´¨é‡é—¨ç¦ï¼Œç¡®ä¿åªæœ‰é«˜è´¨é‡çš„ä»£ç æ‰èƒ½è¿›å…¥ç”Ÿäº§ç¯å¢ƒï¼š

#### ä»£ç æäº¤é—¨ç¦

```json
// .husky/pre-commit
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

echo "ğŸ” Running pre-commit checks..."

# 1. ä»£ç æ ¼å¼æ£€æŸ¥
echo "ğŸ“ Checking code format..."
npm run format:check || {
  echo "âŒ Code format check failed. Run 'npm run format' to fix."
  exit 1
}

# 2. ä»£ç é£æ ¼æ£€æŸ¥
echo "ğŸ¨ Running linter..."
npm run lint || {
  echo "âŒ Linting failed. Please fix the issues above."
  exit 1
}

# 3. ç±»å‹æ£€æŸ¥
echo "ğŸ”§ Type checking..."
npm run type-check || {
  echo "âŒ Type check failed. Please fix the type errors."
  exit 1
}

# 4. å•å…ƒæµ‹è¯•
echo "ğŸ§ª Running unit tests..."
npm run test:unit || {
  echo "âŒ Unit tests failed. Please fix the failing tests."
  exit 1
}

# 5. å®‰å…¨æ£€æŸ¥
echo "ğŸ”’ Security audit..."
npm audit --audit-level moderate || {
  echo "âŒ Security vulnerabilities found. Please fix them."
  exit 1
}

echo "âœ… All pre-commit checks passed!"
```

#### PRåˆå¹¶é—¨ç¦

```yaml
# .github/workflows/pr-checks.yml
name: PR Quality Checks

on:
  pull_request:
    branches: [main, develop]

jobs:
  quality-gate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # è·å–å®Œæ•´å†å²ç”¨äºä»£ç è¦†ç›–ç‡å¯¹æ¯”
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      # è´¨é‡é—¨ç¦1ï¼šä»£ç è¦†ç›–ç‡
      - name: Test Coverage Check
        run: |
          npm run test:coverage
          COVERAGE=$(npm run test:coverage:json | jq '.total.lines.pct')
          if (( $(echo "$COVERAGE < 80" | bc -l) )); then
            echo "âŒ Code coverage ($COVERAGE%) is below 80%"
            exit 1
          fi
          echo "âœ… Code coverage: $COVERAGE%"
      
      # è´¨é‡é—¨ç¦2ï¼šä»£ç å¤æ‚åº¦
      - name: Complexity Check
        run: |
          npx complexity-report --format json src/ > complexity.json
          MAX_COMPLEXITY=$(jq '.reports[].complexity.cyclomatic' complexity.json | sort -nr | head -1)
          if (( $(echo "$MAX_COMPLEXITY > 10" | bc -l) )); then
            echo "âŒ Cyclomatic complexity ($MAX_COMPLEXITY) exceeds limit (10)"
            exit 1
          fi
          echo "âœ… Max complexity: $MAX_COMPLEXITY"
      
      # è´¨é‡é—¨ç¦3ï¼šä»£ç é‡å¤ç‡
      - name: Duplication Check
        run: |
          npx jscpd src/ --threshold 5 --format json > duplication.json
          DUPLICATION=$(jq '.statistics.total.percentage' duplication.json)
          if (( $(echo "$DUPLICATION > 5" | bc -l) )); then
            echo "âŒ Code duplication ($DUPLICATION%) exceeds limit (5%)"
            exit 1
          fi
          echo "âœ… Code duplication: $DUPLICATION%"
      
      # è´¨é‡é—¨ç¦4ï¼šæ€§èƒ½å›å½’æ£€æŸ¥
      - name: Performance Regression Check
        run: |
          npm run build
          npm start &
          sleep 10
          
          # è¿è¡Œæ€§èƒ½æµ‹è¯•
          npx lighthouse http://localhost:3000 --output json --output-path lighthouse.json
          PERFORMANCE=$(jq '.categories.performance.score * 100' lighthouse.json)
          
          if (( $(echo "$PERFORMANCE < 80" | bc -l) )); then
            echo "âŒ Performance score ($PERFORMANCE) is below 80"
            exit 1
          fi
          echo "âœ… Performance score: $PERFORMANCE"
      
      # è´¨é‡é—¨ç¦5ï¼šå®‰å…¨æ¼æ´æ£€æŸ¥
      - name: Security Vulnerability Check
        run: |
          npm audit --audit-level moderate --json > audit.json
          VULNERABILITIES=$(jq '.metadata.vulnerabilities.total' audit.json)
          
          if [ "$VULNERABILITIES" -gt 0 ]; then
            echo "âŒ Found $VULNERABILITIES security vulnerabilities"
            npm audit
            exit 1
          fi
          echo "âœ… No security vulnerabilities found"
```

### 7.5.2 ä»£ç è´¨é‡è¯„ä¼°

#### è‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥

ä½¿ç”¨AIè¾…åŠ©è¿›è¡Œä»£ç å®¡æŸ¥ï¼Œæé«˜å®¡æŸ¥æ•ˆç‡å’Œè´¨é‡ï¼š

```typescript
// scripts/ai-code-review.ts
import { OpenAI } from 'openai';
import { execSync } from 'child_process';
import { readFileSync } from 'fs';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

interface CodeReviewResult {
  file: string;
  issues: Array<{
    line: number;
    type: 'bug' | 'performance' | 'security' | 'maintainability' | 'style';
    severity: 'low' | 'medium' | 'high' | 'critical';
    message: string;
    suggestion: string;
  }>;
  score: number; // 0-100
}

class AICodeReviewer {
  async reviewPullRequest(prNumber: string): Promise<CodeReviewResult[]> {
    // è·å–PRä¸­çš„æ–‡ä»¶å˜æ›´
    const changedFiles = this.getChangedFiles(prNumber);
    const results: CodeReviewResult[] = [];

    for (const file of changedFiles) {
      const content = readFileSync(file, 'utf-8');
      const diff = this.getFileDiff(file, prNumber);
      
      const review = await this.reviewFile(file, content, diff);
      results.push(review);
    }

    return results;
  }

  private async reviewFile(
    filePath: string, 
    content: string, 
    diff: string
  ): Promise<CodeReviewResult> {
    const prompt = `
ä½œä¸ºä¸€ä½èµ„æ·±çš„ä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œè¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç å˜æ›´ï¼š

æ–‡ä»¶è·¯å¾„ï¼š${filePath}
ä»£ç å†…å®¹ï¼š
\`\`\`
${content}
\`\`\`

å˜æ›´å†…å®¹ï¼š
\`\`\`diff
${diff}
\`\`\`

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œå®¡æŸ¥ï¼š
1. **Bugé£é™©**ï¼šæ½œåœ¨çš„é€»è¾‘é”™è¯¯ã€ç©ºæŒ‡é’ˆã€è¾¹ç•Œæ¡ä»¶ç­‰
2. **æ€§èƒ½é—®é¢˜**ï¼šç®—æ³•å¤æ‚åº¦ã€å†…å­˜æ³„æ¼ã€ä¸å¿…è¦çš„è®¡ç®—ç­‰
3. **å®‰å…¨æ¼æ´**ï¼šSQLæ³¨å…¥ã€XSSã€æ•æ„Ÿä¿¡æ¯æ³„éœ²ç­‰
4. **å¯ç»´æŠ¤æ€§**ï¼šä»£ç ç»“æ„ã€å‘½åè§„èŒƒã€æ³¨é‡Šè´¨é‡ç­‰
5. **ä»£ç é£æ ¼**ï¼šæ ¼å¼è§„èŒƒã€æœ€ä½³å®è·µç­‰

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{
  "issues": [
    {
      "line": è¡Œå·,
      "type": "é—®é¢˜ç±»å‹",
      "severity": "ä¸¥é‡ç¨‹åº¦",
      "message": "é—®é¢˜æè¿°",
      "suggestion": "æ”¹è¿›å»ºè®®"
    }
  ],
  "score": ä»£ç è´¨é‡è¯„åˆ†(0-100)
}
`;

    try {
      const response = await openai.chat.completions.create({
        model: 'gpt-4',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.1,
      });

      const result = JSON.parse(response.choices[0].message.content || '{}');
      
      return {
        file: filePath,
        issues: result.issues || [],
        score: result.score || 0,
      };
    } catch (error) {
      console.error(`Failed to review file ${filePath}:`, error);
      return {
        file: filePath,
        issues: [],
        score: 0,
      };
    }
  }

  private getChangedFiles(prNumber: string): string[] {
    try {
      const output = execSync(
        `gh pr diff ${prNumber} --name-only`,
        { encoding: 'utf-8' }
      );
      return output.trim().split('\n').filter(file => 
        file.endsWith('.ts') || file.endsWith('.tsx') || file.endsWith('.js') || file.endsWith('.jsx')
      );
    } catch (error) {
      console.error('Failed to get changed files:', error);
      return [];
    }
  }

  private getFileDiff(file: string, prNumber: string): string {
    try {
      return execSync(
        `gh pr diff ${prNumber} -- ${file}`,
        { encoding: 'utf-8' }
      );
    } catch (error) {
      console.error(`Failed to get diff for ${file}:`, error);
      return '';
    }
  }
}

// ä½¿ç”¨ç¤ºä¾‹
async function main() {
  const reviewer = new AICodeReviewer();
  const prNumber = process.argv[2];
  
  if (!prNumber) {
    console.error('Please provide PR number');
    process.exit(1);
  }

  console.log(`ğŸ” Reviewing PR #${prNumber}...`);
  
  const results = await reviewer.reviewPullRequest(prNumber);
  
  // ç”Ÿæˆå®¡æŸ¥æŠ¥å‘Š
  console.log('\nğŸ“Š Code Review Report\n');
  
  let totalScore = 0;
  let totalIssues = 0;
  
  for (const result of results) {
    console.log(`ğŸ“ ${result.file} (Score: ${result.score}/100)`);
    
    if (result.issues.length === 0) {
      console.log('  âœ… No issues found\n');
    } else {
      result.issues.forEach(issue => {
        const emoji = {
          critical: 'ğŸš¨',
          high: 'âš ï¸',
          medium: 'ğŸ’¡',
          low: 'â„¹ï¸'
        }[issue.severity];
        
        console.log(`  ${emoji} Line ${issue.line}: ${issue.message}`);
        console.log(`     ğŸ’¡ ${issue.suggestion}\n`);
      });
    }
    
    totalScore += result.score;
    totalIssues += result.issues.length;
  }
  
  const avgScore = results.length > 0 ? totalScore / results.length : 0;
  
  console.log(`\nğŸ“ˆ Overall Quality Score: ${avgScore.toFixed(1)}/100`);
  console.log(`ğŸ› Total Issues Found: ${totalIssues}`);
  
  // è®¾ç½®è´¨é‡é—¨ç¦
  if (avgScore < 70) {
    console.log('âŒ Code quality below threshold (70). Please address the issues.');
    process.exit(1);
  }
  
  console.log('âœ… Code quality check passed!');
}

if (require.main === module) {
  main().catch(console.error);
}
```

#### è´¨é‡è¶‹åŠ¿åˆ†æ

```typescript
// lib/quality/trend-analyzer.ts
interface QualityMetrics {
  timestamp: Date;
  codebase: {
    linesOfCode: number;
    testCoverage: number;
    complexity: number;
    duplication: number;
    maintainabilityIndex: number;
  };
  defects: {
    total: number;
    critical: number;
    high: number;
    medium: number;
    low: number;
  };
  performance: {
    buildTime: number;
    testTime: number;
    deployTime: number;
  };
}

class QualityTrendAnalyzer {
  async analyzeQualityTrend(days: number = 30): Promise<{
    trend: 'improving' | 'stable' | 'declining';
    insights: string[];
    recommendations: string[];
  }> {
    const metrics = await this.getHistoricalMetrics(days);
    
    if (metrics.length < 2) {
      return {
        trend: 'stable',
        insights: ['Insufficient data for trend analysis'],
        recommendations: ['Continue collecting quality metrics'],
      };
    }

    const latest = metrics[metrics.length - 1];
    const baseline = metrics[0];
    
    // è®¡ç®—è¶‹åŠ¿æŒ‡æ ‡
    const coverageTrend = this.calculateTrend(
      baseline.codebase.testCoverage,
      latest.codebase.testCoverage
    );
    
    const complexityTrend = this.calculateTrend(
      baseline.codebase.complexity,
      latest.codebase.complexity,
      true // å¤æ‚åº¦è¶Šä½è¶Šå¥½
    );
    
    const defectTrend = this.calculateTrend(
      baseline.defects.total,
      latest.defects.total,
      true // ç¼ºé™·è¶Šå°‘è¶Šå¥½
    );
    
    // ç»¼åˆè¯„ä¼°
    const overallTrend = this.determineOverallTrend([
      coverageTrend,
      complexityTrend,
      defectTrend,
    ]);
    
    const insights = this.generateInsights(metrics);
    const recommendations = this.generateRecommendations(latest, overallTrend);
    
    return {
      trend: overallTrend,
      insights,
      recommendations,
    };
  }

  private calculateTrend(
    baseline: number, 
    current: number, 
    lowerIsBetter: boolean = false
  ): 'improving' | 'stable' | 'declining' {
    const change = ((current - baseline) / baseline) * 100;
    const threshold = 5; // 5%çš„å˜åŒ–é˜ˆå€¼
    
    if (Math.abs(change) < threshold) {
      return 'stable';
    }
    
    if (lowerIsBetter) {
      return change < 0 ? 'improving' : 'declining';
    } else {
      return change > 0 ? 'improving' : 'declining';
    }
  }

  private determineOverallTrend(
    trends: Array<'improving' | 'stable' | 'declining'>
  ): 'improving' | 'stable' | 'declining' {
    const improving = trends.filter(t => t === 'improving').length;
    const declining = trends.filter(t => t === 'declining').length;
    
    if (improving > declining) return 'improving';
    if (declining > improving) return 'declining';
    return 'stable';
  }

  private generateInsights(metrics: QualityMetrics[]): string[] {
    const insights: string[] = [];
    const latest = metrics[metrics.length - 1];
    
    // æµ‹è¯•è¦†ç›–ç‡æ´å¯Ÿ
    if (latest.codebase.testCoverage >= 80) {
      insights.push('æµ‹è¯•è¦†ç›–ç‡è‰¯å¥½ï¼Œè¾¾åˆ°äº†80%ä»¥ä¸Šçš„æ ‡å‡†');
    } else if (latest.codebase.testCoverage >= 60) {
      insights.push('æµ‹è¯•è¦†ç›–ç‡ä¸­ç­‰ï¼Œå»ºè®®æå‡åˆ°80%ä»¥ä¸Š');
    } else {
      insights.push('æµ‹è¯•è¦†ç›–ç‡åä½ï¼Œå­˜åœ¨è´¨é‡é£é™©');
    }
    
    // ä»£ç å¤æ‚åº¦æ´å¯Ÿ
    if (latest.codebase.complexity <= 5) {
      insights.push('ä»£ç å¤æ‚åº¦æ§åˆ¶è‰¯å¥½ï¼Œæ˜“äºç»´æŠ¤');
    } else if (latest.codebase.complexity <= 10) {
      insights.push('ä»£ç å¤æ‚åº¦ä¸­ç­‰ï¼Œéœ€è¦å…³æ³¨é‡æ„æœºä¼š');
    } else {
      insights.push('ä»£ç å¤æ‚åº¦è¿‡é«˜ï¼Œå»ºè®®è¿›è¡Œé‡æ„');
    }
    
    // ç¼ºé™·è¶‹åŠ¿æ´å¯Ÿ
    const recentDefects = metrics.slice(-7); // æœ€è¿‘7å¤©
    const avgDefects = recentDefects.reduce((sum, m) => sum + m.defects.total, 0) / recentDefects.length;
    
    if (avgDefects < 5) {
      insights.push('ç¼ºé™·æ•°é‡æ§åˆ¶è‰¯å¥½ï¼Œè´¨é‡ç¨³å®š');
    } else if (avgDefects < 15) {
      insights.push('ç¼ºé™·æ•°é‡ä¸­ç­‰ï¼Œéœ€è¦åŠ å¼ºæµ‹è¯•');
    } else {
      insights.push('ç¼ºé™·æ•°é‡è¾ƒå¤šï¼Œéœ€è¦é‡ç‚¹å…³æ³¨è´¨é‡æ”¹è¿›');
    }
    
    return insights;
  }

  private generateRecommendations(
    latest: QualityMetrics,
    trend: 'improving' | 'stable' | 'declining'
  ): string[] {
    const recommendations: string[] = [];
    
    // åŸºäºè¶‹åŠ¿çš„å»ºè®®
    switch (trend) {
      case 'improving':
        recommendations.push('è´¨é‡è¶‹åŠ¿è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰çš„å¼€å‘å®è·µ');
        break;
      case 'stable':
        recommendations.push('è´¨é‡ä¿æŒç¨³å®šï¼Œå¯ä»¥è€ƒè™‘å¼•å…¥æ–°çš„æ”¹è¿›æªæ–½');
        break;
      case 'declining':
        recommendations.push('è´¨é‡è¶‹åŠ¿ä¸‹é™ï¼Œéœ€è¦ç«‹å³é‡‡å–æ”¹è¿›æªæ–½');
        break;
    }
    
    // åŸºäºå…·ä½“æŒ‡æ ‡çš„å»ºè®®
    if (latest.codebase.testCoverage < 80) {
      recommendations.push('å¢åŠ å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ï¼Œæå‡æµ‹è¯•è¦†ç›–ç‡');
    }
    
    if (latest.codebase.complexity > 8) {
      recommendations.push('è¯†åˆ«é«˜å¤æ‚åº¦æ¨¡å—ï¼Œè¿›è¡Œé‡æ„ç®€åŒ–');
    }
    
    if (latest.codebase.duplication > 5) {
      recommendations.push('æ¶ˆé™¤é‡å¤ä»£ç ï¼Œæå–å…¬å…±ç»„ä»¶å’Œå·¥å…·å‡½æ•°');
    }
    
    if (latest.defects.critical > 0) {
      recommendations.push('ä¼˜å…ˆä¿®å¤æ‰€æœ‰ä¸¥é‡ç¼ºé™·ï¼Œå»ºç«‹ç¼ºé™·é¢„é˜²æœºåˆ¶');
    }
    
    if (latest.performance.buildTime > 300) { // 5åˆ†é’Ÿ
      recommendations.push('ä¼˜åŒ–æ„å»ºæµç¨‹ï¼Œå‡å°‘æ„å»ºæ—¶é—´');
    }
    
    return recommendations;
  }

  private async getHistoricalMetrics(days: number): Promise<QualityMetrics[]> {
    // è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“æˆ–ç›‘æ§ç³»ç»Ÿè·å–å†å²æ•°æ®
    // ç¤ºä¾‹å®ç°
    return [];
  }
}
```

### 7.5.3 æŒç»­æ”¹è¿›æœºåˆ¶

#### è´¨é‡æ”¹è¿›å·¥ä½œæµ

```typescript
// lib/quality/improvement-workflow.ts
interface QualityIssue {
  id: string;
  type: 'technical_debt' | 'performance' | 'security' | 'maintainability';
  severity: 'low' | 'medium' | 'high' | 'critical';
  description: string;
  impact: string;
  effort: 'small' | 'medium' | 'large';
  assignee?: string;
  status: 'identified' | 'planned' | 'in_progress' | 'resolved' | 'deferred';
  createdAt: Date;
  resolvedAt?: Date;
}

class QualityImprovementWorkflow {
  async identifyImprovementOpportunities(): Promise<QualityIssue[]> {
    const issues: QualityIssue[] = [];
    
    // 1. æŠ€æœ¯å€ºåŠ¡è¯†åˆ«
    const technicalDebt = await this.identifyTechnicalDebt();
    issues.push(...technicalDebt);
    
    // 2. æ€§èƒ½é—®é¢˜è¯†åˆ«
    const performanceIssues = await this.identifyPerformanceIssues();
    issues.push(...performanceIssues);
    
    // 3. å®‰å…¨æ¼æ´è¯†åˆ«
    const securityIssues = await this.identifySecurityIssues();
    issues.push(...securityIssues);
    
    // 4. å¯ç»´æŠ¤æ€§é—®é¢˜è¯†åˆ«
    const maintainabilityIssues = await this.identifyMaintainabilityIssues();
    issues.push(...maintainabilityIssues);
    
    return this.prioritizeIssues(issues);
  }

  private async identifyTechnicalDebt(): Promise<QualityIssue[]> {
    const issues: QualityIssue[] = [];
    
    // æ£€æŸ¥ä»£ç å¤æ‚åº¦
    const complexityReport = await this.analyzeComplexity();
    for (const file of complexityReport.highComplexityFiles) {
      issues.push({
        id: `complexity-${file.path}`,
        type: 'technical_debt',
        severity: file.complexity > 15 ? 'high' : 'medium',
        description: `é«˜å¤æ‚åº¦æ–‡ä»¶: ${file.path} (å¤æ‚åº¦: ${file.complexity})`,
        impact: 'å¢åŠ ç»´æŠ¤æˆæœ¬ï¼Œé™ä½ä»£ç å¯è¯»æ€§',
        effort: file.complexity > 20 ? 'large' : 'medium',
        status: 'identified',
        createdAt: new Date(),
      });
    }
    
    // æ£€æŸ¥ä»£ç é‡å¤
    const duplicationReport = await this.analyzeDuplication();
    for (const duplicate of duplicationReport.duplicates) {
      issues.push({
        id: `duplication-${duplicate.id}`,
        type: 'technical_debt',
        severity: 'medium',
        description: `ä»£ç é‡å¤: ${duplicate.files.join(', ')}`,
        impact: 'å¢åŠ ç»´æŠ¤æˆæœ¬ï¼Œå®¹æ˜“å¼•å…¥ä¸ä¸€è‡´æ€§',
        effort: 'small',
        status: 'identified',
        createdAt: new Date(),
      });
    }
    
    return issues;
  }

  private prioritizeIssues(issues: QualityIssue[]): QualityIssue[] {
    // ä½¿ç”¨åŠ æƒè¯„åˆ†è¿›è¡Œä¼˜å…ˆçº§æ’åº
    const scoreIssue = (issue: QualityIssue): number => {
      const severityWeight = {
        critical: 10,
        high: 7,
        medium: 4,
        low: 1,
      };
      
      const effortWeight = {
        small: 3,
        medium: 2,
        large: 1,
      };
      
      return severityWeight[issue.severity] * effortWeight[issue.effort];
    };
    
    return issues.sort((a, b) => scoreIssue(b) - scoreIssue(a));
  }

  async createImprovementPlan(issues: QualityIssue[]): Promise<{
    sprint1: QualityIssue[];
    sprint2: QualityIssue[];
    backlog: QualityIssue[];
  }> {
    const criticalIssues = issues.filter(i => i.severity === 'critical');
    const highIssues = issues.filter(i => i.severity === 'high');
    const mediumIssues = issues.filter(i => i.severity === 'medium');
    const lowIssues = issues.filter(i => i.severity === 'low');
    
    return {
      sprint1: [...criticalIssues, ...highIssues.slice(0, 3)],
      sprint2: [...highIssues.slice(3), ...mediumIssues.slice(0, 5)],
      backlog: [...mediumIssues.slice(5), ...lowIssues],
    };
  }

  // å…¶ä»–è¾…åŠ©æ–¹æ³•çš„å®ç°...
  private async analyzeComplexity(): Promise<any> {
    // å®ç°å¤æ‚åº¦åˆ†æ
    return { highComplexityFiles: [] };
  }

  private async analyzeDuplication(): Promise<any> {
    // å®ç°é‡å¤ä»£ç åˆ†æ
    return { duplicates: [] };
  }

  private async identifyPerformanceIssues(): Promise<QualityIssue[]> {
    // å®ç°æ€§èƒ½é—®é¢˜è¯†åˆ«
    return [];
  }

  private async identifySecurityIssues(): Promise<QualityIssue[]> {
    // å®ç°å®‰å…¨é—®é¢˜è¯†åˆ«
    return [];
  }

  private async identifyMaintainabilityIssues(): Promise<QualityIssue[]> {
    // å®ç°å¯ç»´æŠ¤æ€§é—®é¢˜è¯†åˆ«
    return [];
  }
}
```

---

## 7.6 æœ¬ç« å°ç»“

æœ¬ç« æ·±å…¥æ¢è®¨äº†DDADç¯å¢ƒä¸‹çš„æµ‹è¯•éƒ¨ç½²ä¸è´¨é‡ä¿è¯ä½“ç³»ï¼Œæ¶µç›–äº†ä»AIé©±åŠ¨çš„æµ‹è¯•ç­–ç•¥åˆ°ç”Ÿäº§ç¯å¢ƒç›‘æ§çš„å®Œæ•´æµç¨‹ã€‚

### æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **AIé©±åŠ¨æµ‹è¯•ç­–ç•¥**
   - æµ‹è¯•èŒƒå¼ä»"äº‹åæ£€éªŒ"è½¬å‘"æµ‹è¯•å‰ç½®"
   - åˆ©ç”¨AIè‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å’Œæµ‹è¯•æ•°æ®
   - å»ºç«‹åˆ†å±‚æµ‹è¯•ä½“ç³»ï¼ˆå•å…ƒâ†’é›†æˆâ†’E2Eï¼‰

2. **è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹**
   - å®Œæ•´çš„CI/CDæµæ°´çº¿è®¾è®¡
   - å¤šç¯å¢ƒéƒ¨ç½²ç­–ç•¥å’Œé…ç½®ç®¡ç†
   - Dockerå®¹å™¨åŒ–å’ŒKubernetesç¼–æ’

3. **ç”Ÿäº§ç¯å¢ƒç›‘æ§**
   - åº”ç”¨æ€§èƒ½ç›‘æ§ï¼ˆAPMï¼‰å’Œè‡ªå®šä¹‰æŒ‡æ ‡
   - ç»“æ„åŒ–æ—¥å¿—ç®¡ç†å’Œä¸šåŠ¡æ—¥å¿—è®°å½•
   - å¥åº·æ£€æŸ¥å’Œæ™ºèƒ½å‘Šè­¦æœºåˆ¶

4. **è´¨é‡ä¿è¯ä½“ç³»**
   - å¤šå±‚æ¬¡è´¨é‡é—¨ç¦æ ‡å‡†
   - AIè¾…åŠ©ä»£ç å®¡æŸ¥å’Œè´¨é‡è¯„ä¼°
   - æŒç»­æ”¹è¿›æœºåˆ¶å’Œè´¨é‡è¶‹åŠ¿åˆ†æ

### DDADä»·å€¼ä½“ç°

- **æ•ˆç‡æå‡**ï¼šè‡ªåŠ¨åŒ–æµ‹è¯•å’Œéƒ¨ç½²å‡å°‘90%çš„æ‰‹åŠ¨å·¥ä½œ
- **è´¨é‡ä¿éšœ**ï¼šAIè¾…åŠ©çš„å…¨é¢è´¨é‡æ£€æŸ¥ç¡®ä¿ä»£ç è´¨é‡
- **å¿«é€Ÿåé¦ˆ**ï¼šå®æ—¶ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶å¿«é€Ÿå‘ç°é—®é¢˜
- **æŒç»­æ”¹è¿›**ï¼šæ•°æ®é©±åŠ¨çš„è´¨é‡æ”¹è¿›å†³ç­–

### å®è·µå»ºè®®

1. **æ¸è¿›å¼å®æ–½**ï¼šä»æ ¸å¿ƒåŠŸèƒ½å¼€å§‹ï¼Œé€æ­¥æ‰©å±•æµ‹è¯•è¦†ç›–
2. **å·¥å…·æ•´åˆ**ï¼šé€‰æ‹©åˆé€‚çš„å·¥å…·é“¾ï¼Œç¡®ä¿å·¥å…·é—´çš„è‰¯å¥½é›†æˆ
3. **å›¢é˜ŸåŸ¹è®­**ï¼šæå‡å›¢é˜Ÿå¯¹æ–°å·¥å…·å’Œæµç¨‹çš„ç†è§£å’Œä½¿ç”¨èƒ½åŠ›
4. **åº¦é‡é©±åŠ¨**ï¼šå»ºç«‹å®Œå–„çš„è´¨é‡åº¦é‡ä½“ç³»ï¼Œç”¨æ•°æ®æŒ‡å¯¼æ”¹è¿›

é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œä½ åº”è¯¥èƒ½å¤Ÿå»ºç«‹ä¸€å¥—å®Œæ•´çš„DDADè´¨é‡ä¿è¯ä½“ç³»ï¼Œç¡®ä¿AIç”Ÿæˆçš„ä»£ç åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¨³å®šå¯é åœ°è¿è¡Œã€‚ä¸‹ä¸€ç« æˆ‘ä»¬å°†æ¢è®¨å›¢é˜Ÿåä½œä¸AIåä½œæ²»ç†ï¼Œå­¦ä¹ å¦‚ä½•åœ¨å›¢é˜Ÿç¯å¢ƒä¸­æœ‰æ•ˆå®æ–½DDADã€‚